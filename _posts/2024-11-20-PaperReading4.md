---
layout:     post
title:      "【论文速读】| RePD：通过基于检索的提示分解过程防御越狱攻击"
date:       2024-11-20 16:30:00
author:     "安全极客"
header-img: "img/post-bg-unix-linux.jpg"
tags:
    - Security
    - AIGC
    - 论文速读
---


![这是一张图片](https://www.gptsecurity.info/img/in-post/0807/01.jpg)

## 基本信息

**原文标题**：RePD: Defending Jailbreak Attack through a Retrieval-based Prompt Decomposition Process

**原文作者**：Peiran Wang, Xiaogeng Liu, Chaowei Xiao

**作者单位**：University of Wisconsin–Madison

**关键词**：越狱攻击，大语言模型，提示分解，基于检索的防御

**原文链接**：https://arxiv.org/pdf/2410.08660

**开源代码**：暂无

## 论文要点

**论文简介**：这篇论文提出了一种创新性的防御框架——RePD，用于应对针对大语言模型（LLMs）的越狱攻击。尽管LLMs经过大量的训练以符合道德和安全准则，越狱攻击仍能使模型输出有害的内容。RePD通过检索事先收集的越狱提示模板，将用户的越狱攻击提示解构并分离，从而中和潜在的恶意问题，再根据模型的安全准则生成合适的响应。该方法在保证防御有效性的同时，不影响模型处理正常请求的性能。

**研究目的**：本研究旨在解决大语言模型在应对越狱攻击时面临的挑战。这些攻击通过复杂的模板隐藏恶意问题，从而绕过模型的安全过滤机制。传统的防御手段要么代价高昂，要么容易产生误判或计算开销过大。RePD的目标是在不显著增加计算成本的情况下，构建一种能够有效防御越狱攻击并且兼容各种开源LLMs的解决方案。

## 引言

近年来，大语言模型（LLMs）在处理各种任务上表现出色，但同时也引发了严重的安全和伦理问题。即使经过精细调优以增强对有害内容的防御，LLMs仍然容易被所谓的“越狱攻击”所利用。越狱攻击通过设计巧妙的提示，将恶意问题隐藏在表面看似无害的内容中，绕过模型的安全协议，从而生成有害内容。这种攻击引发了对模型安全性的广泛关注。

现有的防御方法大多侧重于通过附加提示或过滤器来检测和拦截有害内容，然而这些方法通常存在高计算成本，或在过滤过程中导致过多的误报，拒绝正常的用户请求。此外，许多方法依赖复杂的多模型结构，进一步增加了响应时间和资源消耗。基于这些问题，论文提出了一种新颖的防御框架RePD，旨在通过提示分解和检索技术来有效抵御越狱攻击。

## 相关工作

近年来，关于越狱攻击的研究越来越多。传统的越狱攻击主要通过模板插入的方式，将恶意问题嵌入到特定的角色扮演场景或编码格式中。这些模板帮助攻击者引导大语言模型生成有害的回应，成功规避模型的安全对齐机制。为了应对此类威胁，许多防御方法被提出，例如通过调整模型的系统提示或附加特定前缀来提醒模型保持安全。然而，这些方法在某些情况下会影响模型的正常输出，或者需要额外的计算资源。

还有一些方法尝试直接检测或过滤有害提示，但同样存在精度不足或误报率高的问题。相比之下，RePD通过提示分解的方式，将复杂的越狱攻击提示分离成有害问题和其他无害的部分，从而有效地提高了防御效果。

## 研究方法

RePD框架的核心方法围绕基于检索的提示分解技术展开，主要分为三个步骤：提示检索、提示分解和生成响应。这种方法的目标是有效防御大语言模型（LLMs）面临的越狱攻击。



1. 提示检索：当用户输入一个提示后，RePD首先会从一个预先建立的越狱提示模板数据库中检索与该提示最为相似的越狱模板。这些模板是由多种常见的越狱攻击模式（如角色扮演、Base64编码等）构成的，通过匹配的方式，RePD能够迅速找到可能包含恶意问题的模板。2. 提示分解：一旦找到匹配的越狱模板，RePD会将用户输入的提示分解为两部分：一部分是嵌入的越狱模板，另一部分是潜在的恶意问题。这个分解过程非常重要，因为越狱攻击通常会通过复杂的模板掩盖恶意问题，RePD通过这一步骤使得模型能够明确识别出隐藏的威胁。3. 生成响应：在成功分解提示后，RePD将恶意问题与越狱模板隔离，并基于无害部分生成符合道德和安全规范的响应。在实际应用中，这意味着模型能够有效过滤掉恶意问题，而对普通的、无害的提示继续生成合规的答案。此外，RePD使用了一种“一次性学习”机制，即通过检索到的越狱模板为模型提供示例，使得它能够快速学习如何处理类似的越狱攻击。通过这一流程，RePD框架能够在不需要对LLMs进行复杂再训练的情况下，实现对越狱攻击的有效防御，同时确保对正常请求的响应不会受到影响。这种基于提示分解的防御方式具备高效性、低误报率和良好的通用性。研究评估在研究评估部分，论文通过对RePD框架的全面实验验证，展示了其在防御越狱攻击中的有效性。实验使用了两种对齐的大语言模型（LLaMA-2-7B-Chat和Vicuna-7B-V1.5）进行测试，并采用了一系列的越狱攻击方法，包括自适应攻击、编码攻击和嵌入模板攻击，以确保评估的全面性和真实性。评估结果显示，RePD能够显著降低越狱攻击的成功率（Attack Success Rate, ASR），相比其他防御方法，RePD的ASR降低了87.2%。此外，在防御过程中，RePD还保持了较低的误报率（False Positive Rate, FPR），即对无害提示的误判率仅为8.2%，表明该框架在确保安全的同时，不会影响正常用户请求的处理。这种平衡体现了RePD的精确性和实用性。论文还比较了RePD与其他现有防御机制的性能，如“自我提醒”和“安全提示”等方法，结果表明RePD在攻击成功率、误报率以及整体准确性方面都有显著优势。同时，RePD的多智能体版本（RePD-M）在防御性能上进一步提升，尽管会增加少量的计算开销，但防御效果更为突出。整体评估表明，RePD能够在各种复杂的越狱攻击下有效提升大语言模型的安全性，且对模型的正常功能影响较小，是一种具有广泛应用前景的防御方法。论文结论RePD通过基于检索的提示分解策略，为防御大语言模型的越狱攻击提供了一种高效且低成本的解决方案。与传统方法相比，RePD无需耗费大量资源进行模型再训练，也不会影响模型处理正常请求的能力。通过实验证明，RePD在降低攻击成功率和误报率方面表现卓越，为未来的大语言模型安全提供了新的思路。

原作者：论文解读智能体

校对：小椰风

![这是一张图片](https://www.gptsecurity.info/img/in-post/0813/08.webp)







